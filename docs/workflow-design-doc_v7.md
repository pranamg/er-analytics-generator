# ER Diagram to Analytics Platform
## Workflow Design Document

**Version:** 1.0  
**Date:** December 18, 2025  
**Author:** Analytics Pipeline System

---

## Executive Summary

This document describes the complete workflow for transforming an ER diagram image into a production-ready analytics platform with dashboards, documentation, and deployment scripts. The pipeline consists of 11 stages organized in series and parallel execution paths.

---

## Workflow Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         MAIN PIPELINE FLOW                          â”‚
â”‚                                                                     â”‚
â”‚  [Input] â”€â”€â–º Stage 1 â”€â”€â–º Stage 2 â”€â”€â”¬â”€â”€â–º Stage 3 â”€â”€â–º Stage 4 â”€â”€â”   â”‚
â”‚                                     â”‚                            â”‚   â”‚
â”‚                                     â””â”€â”€â–º Stage 5 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚                                                                  â”‚   â”‚
â”‚                                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                     â”‚                                â”‚
â”‚                                     â”œâ”€â”€â–º Stage 6 â”€â”€â–º Stage 7 â”€â”€â”    â”‚
â”‚                                     â”‚                           â”‚    â”‚
â”‚                                     â”œâ”€â”€â–º Stage 8 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚                                     â”‚                           â”‚    â”‚
â”‚                                     â”œâ”€â”€â–º Stage 9 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚                                     â”‚                           â”‚    â”‚
â”‚                                     â””â”€â”€â–º Stage 10 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚                                                                 â”‚    â”‚
â”‚                                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                     â”‚                                â”‚
â”‚                                     â””â”€â”€â–º [Output: Complete System]   â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Execution Model:**
- **Series:** Stages 1, 2, 3, 4 (must execute sequentially)
- **Parallel:** Stages 6-10 (can execute simultaneously after Stage 5)
- **Independent:** Stage 11 (can run anytime)

---

## Stage-by-Stage Workflow

### ğŸ“Š **STAGE 1: Vision API - ER Diagram Parser**

**Type:** Entry Point | Sequential  
**Execution Time:** ~5-10 seconds  
**Technology:** Claude Vision API, Python/JavaScript

#### Input:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ER Diagram Image                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Format: PNG, JPG, JPEG        â”‚
â”‚ â€¢ Resolution: Min 800x600       â”‚
â”‚ â€¢ Quality: Clear, readable text â”‚
â”‚ â€¢ File Size: < 10MB             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Process:
1. **Image Encoding**
   - Convert image to base64
   - Determine MIME type
   
2. **API Request**
   - Send to Claude Vision API
   - Prompt for schema extraction
   - Request JSON format
   
3. **Response Processing**
   - Parse JSON response
   - Validate schema structure
   - Clean markdown artifacts

4. **Schema Validation**
   - Verify table names
   - Check column definitions
   - Validate relationships

#### Output:
```json
{
  "tables": [
    {
      "name": "TableName",
      "columns": [
        {
          "name": "column_name",
          "type": "DATA_TYPE",
          "primaryKey": true/false,
          "foreignKey": "RefTable(refColumn)" | null
        }
      ]
    }
  ]
}
```

#### Success Criteria:
- âœ“ All tables extracted
- âœ“ Primary keys identified
- âœ“ Foreign keys mapped
- âœ“ Valid JSON structure

#### Error Handling:
- Invalid image â†’ Retry with different format
- Incomplete extraction â†’ Manual review required
- API timeout â†’ Exponential backoff retry

---

### ğŸ—„ï¸ **STAGE 2: Schema Processor**

**Type:** Sequential  
**Execution Time:** < 1 second  
**Technology:** JavaScript/Python

#### Input:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Parsed Schema (JSON)            â”‚
â”‚ from Stage 1                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Process:
1. **Schema Validation**
   - Check for circular dependencies
   - Validate data types
   - Verify referential integrity rules

2. **Schema Enhancement**
   - Infer missing data types
   - Add default constraints
   - Generate index recommendations

3. **Metadata Generation**
   - Table count
   - Column count per table
   - Relationship count
   - Complexity score

4. **Dependency Graph**
   - Build table dependency tree
   - Identify root tables
   - Order for data generation

#### Output:
```json
{
  "schema": { /* enhanced schema */ },
  "metadata": {
    "tableCount": 12,
    "totalColumns": 45,
    "relationships": 11,
    "complexity": "medium"
  },
  "dependencyOrder": [
    "Ref_SIC_Codes",
    "Ref_Invoice_Status",
    "Agencies",
    "Clients",
    ...
  ]
}
```

#### Success Criteria:
- âœ“ No circular dependencies
- âœ“ All foreign keys resolvable
- âœ“ Valid dependency order

---

### ğŸ’¾ **STAGE 3: SQL DDL Generator**

**Type:** Sequential  
**Execution Time:** < 1 second  
**Technology:** Template Engine (Jinja2/JavaScript)

#### Input:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Enhanced Schema (JSON)          â”‚
â”‚ from Stage 2                    â”‚
â”‚                                 â”‚
â”‚ Optional Parameters:            â”‚
â”‚ â€¢ Target DB: PostgreSQL/MySQL   â”‚
â”‚ â€¢ Include Views: true/false     â”‚
â”‚ â€¢ Include Indexes: true/false   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Process:
1. **Table Creation Statements**
   ```sql
   CREATE TABLE TableName (
       column_name DATA_TYPE [PRIMARY KEY],
       ...
   );
   ```

2. **Foreign Key Constraints**
   ```sql
   ALTER TABLE TableName
       ADD FOREIGN KEY (column) 
       REFERENCES RefTable(refColumn);
   ```

3. **Index Generation**
   ```sql
   CREATE INDEX idx_table_column 
       ON TableName(column_name);
   ```

4. **View Creation**
   ```sql
   CREATE VIEW view_name AS
   SELECT ...
   FROM ...
   JOIN ...;
   ```

5. **Database-Specific Optimizations**
   - PostgreSQL: SERIAL types, tablespaces
   - MySQL: ENGINE=InnoDB, AUTO_INCREMENT
   - SQL Server: IDENTITY columns

#### Output:
```sql
-- schema.sql
-- Generated: 2025-12-18
-- Tables: 12
-- Total Lines: ~250

CREATE TABLE Agencies (...);
CREATE TABLE Clients (...);
...
ALTER TABLE Clients ADD FOREIGN KEY ...;
...
CREATE INDEX idx_invoices_date ON Invoices(invoice_date);
...
CREATE VIEW client_revenue_summary AS ...;
```

**File Output:**
- `schema.sql` (complete DDL)
- `schema_postgresql.sql` (PostgreSQL-specific)
- `schema_mysql.sql` (MySQL-specific)

#### Success Criteria:
- âœ“ Syntactically valid SQL
- âœ“ All tables created
- âœ“ All constraints defined
- âœ“ Executable without errors

---

### ğŸ² **STAGE 4: Synthetic Data Generator**

**Type:** Sequential (depends on Stage 2 dependency order)  
**Execution Time:** 2-5 seconds  
**Technology:** Faker.js, NumPy, Pandas

#### Input:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Enhanced Schema (JSON)          â”‚
â”‚ from Stage 2                    â”‚
â”‚                                 â”‚
â”‚ Parameters:                     â”‚
â”‚ â€¢ Row counts per table          â”‚
â”‚ â€¢ Date ranges                   â”‚
â”‚ â€¢ Distribution rules            â”‚
â”‚ â€¢ Referential integrity rules   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Process:
1. **Data Generation Strategy**
   ```
   For each table in dependencyOrder:
       1. Determine row count (rules-based or random)
       2. Generate primary keys (sequential/UUID)
       3. For each column:
          - If FK: select from parent table
          - If date: generate in range
          - If text: use Faker library
          - If number: use distribution (normal/uniform)
       4. Validate referential integrity
       5. Write to memory/CSV
   ```

2. **Reference Tables First**
   - Ref_SIC_Codes (5 rows)
   - Ref_Invoice_Status (3 rows)
   - Ref_Meeting_Types (4 rows)
   - Ref_Meeting_Outcomes (4 rows)

3. **Parent Tables Second**
   - Agencies (6 rows)
   - Staff (12 rows)

4. **Child Tables Third**
   - Clients (15 rows, FK to Agencies)
   - Meetings (60 rows, FK to Clients)
   - Invoices (50 rows, FK to Clients)

5. **Junction Tables Last**
   - Staff_in_Meetings (FK to both)
   - Payments (FK to Invoices)

6. **Data Realism Rules**
   - **Dates:** Clients signup 0-12 months ago
   - **Meetings:** After client signup
   - **Invoices:** Match meeting timeline
   - **Payments:** 5-30 days after invoice
   - **Amounts:** Realistic distributions ($5K-$55K)

#### Output:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CSV Files (11 files)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ agencies.csv           (6 rows) â”‚
â”‚ clients.csv           (15 rows) â”‚
â”‚ staff.csv             (12 rows) â”‚
â”‚ meetings.csv          (60 rows) â”‚
â”‚ invoices.csv          (50 rows) â”‚
â”‚ payments.csv          (30 rows) â”‚
â”‚ staff_in_meetings.csv (90 rows) â”‚
â”‚ ref_sic_codes.csv      (5 rows) â”‚
â”‚ ref_invoice_status.csv (3 rows) â”‚
â”‚ ref_meeting_types.csv  (4 rows) â”‚
â”‚ ref_meeting_outcomes.csv (4 rows)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Total Records: ~279
CSV Format: UTF-8, comma-delimited, headers
```

#### Success Criteria:
- âœ“ All foreign keys valid
- âœ“ No orphaned records
- âœ“ Realistic data distributions
- âœ“ Date logic consistent

---

### ğŸ“‹ **STAGE 5: Requirements Document Generator**

**Type:** Sequential  
**Execution Time:** < 1 second  
**Technology:** Template Engine

#### Input:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Enhanced Schema (JSON)          â”‚
â”‚ from Stage 2                    â”‚
â”‚                                 â”‚
â”‚ Table Metadata:                 â”‚
â”‚ â€¢ Business domain (inferred)    â”‚
â”‚ â€¢ Table relationships           â”‚
â”‚ â€¢ Complexity metrics            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Process:
1. **Analyze Schema for Business Context**
   - Identify business entities (Clients, Invoices, etc.)
   - Determine business domain (advertising agency)
   - Extract key metrics (revenue, meetings, etc.)

2. **Generate Questions by Stakeholder Level**
   
   **Basic Questions (Operational Staff):**
   - Simple counts: "How many X?"
   - Basic filters: "Which Y have status Z?"
   - Current state: "What is the current X?"
   
   **Intermediate Questions (Managers):**
   - Aggregations: "What is average X by Y?"
   - Comparisons: "How does X compare to Y?"
   - Time-based: "What is the trend of X?"
   
   **Advanced Questions (Executives):**
   - Multi-dimensional: "How does X correlate with Y controlling for Z?"
   - Predictive: "What are the drivers of X?"
   - Optimization: "What is the optimal X for Y?"

3. **Map Questions to Tables**
   - Identify required tables for each question
   - Determine SQL complexity
   - Specify answer type

#### Output:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Requirements Document                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                             â”‚
â”‚ OPERATIONAL STAFF (Basic Level)            â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•            â”‚
â”‚ 1. How many active clients do we have?     â”‚
â”‚    Type: Single Metric                      â”‚
â”‚    SQL: Simple                              â”‚
â”‚    Tables: [Clients]                        â”‚
â”‚                                             â”‚
â”‚ 2. Which agencies have the most clients?   â”‚
â”‚    Type: Ranked List                        â”‚
â”‚    SQL: Simple                              â”‚
â”‚    Tables: [Agencies, Clients]              â”‚
â”‚                                             â”‚
â”‚ ... (5 questions total)                     â”‚
â”‚                                             â”‚
â”‚ MANAGERS (Intermediate Level)               â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•              â”‚
â”‚ 1. What is average invoice value by agency?â”‚
â”‚    Type: Comparative Metrics                â”‚
â”‚    SQL: Moderate                            â”‚
â”‚    Tables: [Agencies, Clients, Invoices]    â”‚
â”‚                                             â”‚
â”‚ ... (6 questions total)                     â”‚
â”‚                                             â”‚
â”‚ EXECUTIVES (Advanced Level)                 â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                 â”‚
â”‚ 1. What is CLV by industry segment?        â”‚
â”‚    Type: Advanced Metric                    â”‚
â”‚    SQL: Complex                             â”‚
â”‚    Tables: [Clients, Invoices, Payments]    â”‚
â”‚                                             â”‚
â”‚ ... (6 questions total)                     â”‚
â”‚                                             â”‚
â”‚ TOTAL QUESTIONS: 17                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**File Output:**
- `requirements_document.txt`
- `requirements_document.json` (structured)

#### Success Criteria:
- âœ“ Questions cover all stakeholder levels
- âœ“ Questions map to available data
- âœ“ SQL complexity accurately assessed

---

## Parallel Processing Branch

**After Stage 5, the following stages can execute in parallel:**

---

### ğŸ“„ **STAGE 6: PRD Generator**

**Type:** Parallel (after Stage 5)  
**Execution Time:** < 1 second  
**Technology:** Template Engine, Document Generator

#### Input:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Requirements Document           â”‚
â”‚ from Stage 5                    â”‚
â”‚                                 â”‚
â”‚ Enhanced Schema                 â”‚
â”‚ from Stage 2                    â”‚
â”‚                                 â”‚
â”‚ Optional:                       â”‚
â”‚ â€¢ Company name                  â”‚
â”‚ â€¢ Project timeline              â”‚
â”‚ â€¢ Budget constraints            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Process:
1. **Section 1: Executive Summary**
   - Auto-generate from schema analysis
   - Include table count, complexity
   - State primary objectives

2. **Section 2: Business Context**
   - Infer business domain
   - State industry challenges
   - Define success criteria

3. **Section 3: Stakeholder Profiles**
   - Extract from requirements document
   - Map to organizational roles
   - Define access levels

4. **Section 4: Functional Requirements**
   - Data integration requirements
   - Dashboard capabilities
   - Advanced analytics features
   - Reporting capabilities

5. **Section 5: Dashboard Specifications**
   - One spec per dashboard type
   - List KPIs and visualizations
   - Define filters and drill-downs

6. **Section 6: Data Requirements**
   - Refresh frequency
   - Data retention policies
   - Performance SLAs

7. **Section 7: Success Metrics**
   - Platform adoption KPIs
   - Business impact metrics

8. **Section 8: Technical Stack**
   - Frontend recommendations
   - Backend recommendations
   - Database recommendations
   - BI tool recommendations

#### Output:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PRD_advertising_agency_analytics.txt        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                             â”‚
â”‚ Product Requirements Document               â”‚
â”‚ Advertising Agency Analytics Platform       â”‚
â”‚                                             â”‚
â”‚ Version: 1.0                                â”‚
â”‚ Date: 2025-12-18                            â”‚
â”‚                                             â”‚
â”‚ 1. EXECUTIVE SUMMARY                        â”‚
â”‚    This platform provides comprehensive...  â”‚
â”‚                                             â”‚
â”‚ 2. BUSINESS CONTEXT                         â”‚
â”‚    Advertising agencies manage complex...   â”‚
â”‚                                             â”‚
â”‚ 3. STAKEHOLDER PROFILES                     â”‚
â”‚    3.1 Operational Staff                    â”‚
â”‚        Needs: Basic-level analytics...      â”‚
â”‚                                             â”‚
â”‚ ... (8 sections total, ~2000 words)         â”‚
â”‚                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**File Outputs:**
- `PRD_advertising_agency_analytics.txt`
- `PRD_advertising_agency_analytics.pdf` (formatted)
- `PRD_advertising_agency_analytics.docx` (editable)

#### Success Criteria:
- âœ“ All 8 sections completed
- âœ“ Specific to schema domain
- âœ“ Actionable requirements
- âœ“ Ready for development handoff

---

### ğŸ“Š **STAGE 7: Advanced Analytics Engine**

**Type:** Parallel (after Stage 5)  
**Execution Time:** 1-2 seconds  
**Technology:** Python, Pandas, NumPy

#### Input:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Synthetic Data (CSV files)      â”‚
â”‚ from Stage 4                    â”‚
â”‚                                 â”‚
â”‚ Specifically Required:          â”‚
â”‚ â€¢ clients.csv (with signup_date)â”‚
â”‚ â€¢ invoices.csv (with dates)     â”‚
â”‚ â€¢ payments.csv (with dates)     â”‚
â”‚ â€¢ meetings.csv                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Process:

**1. Cohort Analysis**
```python
# Group clients by signup month
cohorts = clients.groupby(
    clients['signup_date'].dt.to_period('M')
)

# For each cohort, calculate retention
for cohort_month, cohort_clients in cohorts:
    for offset in range(7):  # Month 0-6
        target_month = cohort_month + offset
        
        # Count active clients in target month
        active = invoices[
            (invoices['client_id'].isin(cohort_clients)) &
            (invoices['invoice_date'].dt.to_period('M') == target_month)
        ]['client_id'].nunique()
        
        retention_rate = active / len(cohort_clients) * 100
```

**2. Retention Curve**
- Calculate average retention across all cohorts
- Generate month-over-month retention data
- Identify retention benchmarks

**3. Revenue Cohort Analysis**
- Total revenue by cohort
- Revenue per client by cohort
- Cohort LTV calculation

**4. Churn Risk Scoring**
- Identify clients without recent activity
- Score based on engagement metrics
- Flag high-risk clients

#### Output:
```json
{
  "cohortAnalysis": {
    "cohorts": [
      {
        "month": "2024-12",
        "size": 3,
        "retention": [
          {"month": 0, "rate": 100, "count": 3},
          {"month": 1, "rate": 100, "count": 3},
          {"month": 2, "rate": 66.7, "count": 2},
          ...
        ]
      }
    ],
    "averageRetention": [
      {"month": 0, "rate": 100},
      {"month": 1, "rate": 95.2},
      {"month": 2, "rate": 87.3},
      ...
    ]
  },
  "revenueCohorts": [
    {
      "cohort": "Dec 24",
      "revenue": 145000,
      "clientCount": 3,
      "revenuePerClient": 48333
    }
  ],
  "churnRisk": [
    {
      "client_id": 5,
      "client_name": "HealthCare Plus",
      "risk_score": 0.82,
      "last_activity": "2024-09-15",
      "days_inactive": 95
    }
  ]
}
```

**Visualization Data:**
- Retention curves (line charts)
- Cohort heatmaps
- Revenue trends by cohort
- Churn risk distribution

#### Success Criteria:
- âœ“ All cohorts analyzed
- âœ“ Retention curves generated
- âœ“ Revenue metrics calculated
- âœ“ Churn scores assigned

---

### ğŸ“ˆ **STAGE 8: Dashboard Builder**

**Type:** Parallel (after Stage 5)  
**Execution Time:** < 1 second  
**Technology:** React, Recharts, D3.js

#### Input:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Synthetic Data (CSV files)      â”‚
â”‚ from Stage 4                    â”‚
â”‚                                 â”‚
â”‚ Requirements Document           â”‚
â”‚ from Stage 5                    â”‚
â”‚                                 â”‚
â”‚ Advanced Analytics              â”‚
â”‚ from Stage 7 (optional)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Process:

**1. Data Aggregation**
```javascript
// Calculate KPIs
const kpis = {
    totalClients: clients.length,
    totalRevenue: invoices.reduce((sum, inv) => sum + inv.amount, 0),
    totalMeetings: meetings.length,
    paymentRate: (payments.length / invoices.length) * 100
};

// Revenue by Agency
const revenueByAgency = agencies.map(agency => ({
    name: agency.agency_details,
    revenue: invoices
        .filter(inv => clients
            .find(c => c.client_id === inv.client_id)
            ?.agency_id === agency.agency_id
        )
        .reduce((sum, inv) => sum + inv.amount, 0)
}));
```

**2. Dashboard Creation (4 Types)**

**Executive Dashboard:**
- KPIs: Clients, Revenue, Payment Rate, Avg Invoice
- Charts: Revenue by Agency, Industry Distribution, Revenue Trend, Meeting Outcomes

**Finance Dashboard:**
- KPIs: Total Revenue, Outstanding AR, Payment Rate, Invoices
- Charts: Invoice Status, AR Aging, Revenue Trend, Payment Velocity

**Operations Dashboard:**
- KPIs: Staff Count, Meetings, Utilization, Clients
- Charts: Staff Utilization, Billable Split, Meeting Outcomes, Client Distribution

**Sales Dashboard:**
- KPIs: Active Clients, Meetings, Revenue/Client, Success Rate
- Charts: Revenue by Agency, Client Distribution, Meeting Outcomes, Revenue Trends

**3. Visualization Component Generation**
```javascript
// Example: Bar Chart Component
<BarChart data={revenueByAgency}>
    <CartesianGrid strokeDasharray="3 3" />
    <XAxis dataKey="name" />
    <YAxis />
    <Tooltip />
    <Bar dataKey="revenue" fill="#3b82f6" />
</BarChart>
```

#### Output:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Interactive Dashboards (4)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                             â”‚
â”‚ 1. Executive Dashboard                      â”‚
â”‚    â€¢ 4 KPI cards                            â”‚
â”‚    â€¢ 4 visualizations                       â”‚
â”‚    â€¢ Real-time data binding                 â”‚
â”‚                                             â”‚
â”‚ 2. Finance Dashboard                        â”‚
â”‚    â€¢ 4 KPI cards                            â”‚
â”‚    â€¢ 4 visualizations (incl. AR aging)      â”‚
â”‚    â€¢ Drill-down capabilities                â”‚
â”‚                                             â”‚
â”‚ 3. Operations Dashboard                     â”‚
â”‚    â€¢ 4 KPI cards                            â”‚
â”‚    â€¢ 4 visualizations (incl. utilization)   â”‚
â”‚    â€¢ Staff performance tracking             â”‚
â”‚                                             â”‚
â”‚ 4. Sales Dashboard                          â”‚
â”‚    â€¢ 4 KPI cards                            â”‚
â”‚    â€¢ 4 visualizations (incl. pipeline)      â”‚
â”‚    â€¢ Client engagement metrics              â”‚
â”‚                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Deliverables:**
- React components (JSX files)
- Standalone HTML dashboards
- Dashboard screenshots (PNG)
- Usage documentation

#### Success Criteria:
- âœ“ All 4 dashboards functional
- âœ“ Data accurately displayed
- âœ“ Interactive features working
- âœ“ Mobile responsive

---

### ğŸ“¦ **STAGE 9: Power BI Exporter**

**Type:** Parallel (after Stage 5)  
**Execution Time:** < 1 second  
**Technology:** DAX, Power Query M

#### Input:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Enhanced Schema                 â”‚
â”‚ from Stage 2                    â”‚
â”‚                                 â”‚
â”‚ Synthetic Data (CSV files)      â”‚
â”‚ from Stage 4                    â”‚
â”‚                                 â”‚
â”‚ Requirements Document           â”‚
â”‚ from Stage 5                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Process:

**1. Generate DAX Measures**
```dax
// Revenue Measures
Total Revenue = SUM(Invoices[amount])

Total Payments = SUM(Payments[amount])

Payment Rate = DIVIDE([Total Payments], [Total Revenue], 0)

// Client Measures
Total Clients = DISTINCTCOUNT(Clients[client_id])

Active Clients = 
CALCULATE(
    DISTINCTCOUNT(Meetings[client_id]),
    DATESINPERIOD('Date'[Date], MAX('Date'[Date]), -1, MONTH)
)

// CLV Measure
Client Lifetime Value = 
CALCULATE(
    [Total Revenue],
    ALLEXCEPT(Clients, Clients[client_id])
)

// Retention Measure
Retention Rate = 
VAR ClientsLastMonth = 
    CALCULATE(
        DISTINCTCOUNT(Clients[client_id]),
        DATEADD('Date'[Date], -1, MONTH)
    )
VAR ClientsStillActive = 
    CALCULATE(
        DISTINCTCOUNT(Clients[client_id]),
        FILTER(ALL('Date'), 'Date'[Date] = MAX('Date'[Date]))
    )
RETURN DIVIDE(ClientsStillActive, ClientsLastMonth, 0)
```

**2. Generate Power Query M Code**
```m
// Date Table
let
    StartDate = #date(2023, 1, 1),
    EndDate = #date(2025, 12, 31),
    NumberOfDays = Duration.Days(EndDate - StartDate) + 1,
    DateList = List.Dates(StartDate, NumberOfDays, #duration(1,0,0,0)),
    #"Converted to Table" = Table.FromList(
        DateList, 
        Splitter.SplitByNothing(), 
        {"Date"}
    ),
    #"Added Year" = Table.AddColumn(
        #"Converted to Table", 
        "Year", 
        each Date.Year([Date])
    ),
    #"Added Month" = Table.AddColumn(
        #"Added Year", 
        "Month", 
        each Date.Month([Date])
    )
in
    #"Added Month"
```

**3. Create Relationship Instructions**
```
Relationships to Create:
1. Clients[agency_id] â†’ Agencies[agency_id] (Many-to-One, Both)
2. Clients[sic_code] â†’ Ref_SIC_Codes[sic_code] (Many-to-One, Both)
3. Invoices[client_id] â†’ Clients[client_id] (Many-to-One, Both)
4. Invoices[invoice_status_code] â†’ Ref_Invoice_Status[invoice_status_code] (Many-to-One, Both)
5. Payments[invoice_id] â†’ Invoices[invoice_id] (Many-to-One, Both)
6. Meetings[client_id] â†’ Clients[client_id] (Many-to-One, Both)
7. Meetings[meeting_type_code] â†’ Ref_Meeting_Types[meeting_type_code] (Many-to-One, Both)
8. Meetings[meeting_outcome_code] â†’ Ref_Meeting_Outcomes[meeting_outcome_code] (Many-to-One, Both)
9. Staff[agency_id] â†’ Agencies[agency_id] (Many-to-One, Both)
10. Staff_in_Meetings[meeting_id] â†’ Meetings[meeting_id] (Many-to-One, Both)
11. Staff_in_Meetings[staff_id] â†’ Staff[staff_id] (Many-to-One, Both)
```

**4. Create Import Guide**
- Step-by-step CSV import
- Relationship configuration
- Measure creation
- Dashboard template setup

#### Output:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Power BI Resources                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                             â”‚
â”‚ Files Generated:                            â”‚
â”‚ â€¢ power_bi_measures.dax (15+ measures)      â”‚
â”‚ â€¢ power_bi_date_table.m (Power Query)       â”‚
â”‚ â€¢ power_bi_instructions.md (guide)          â”‚
â”‚ â€¢ power_bi_relationships.txt (mappings)     â”‚
â”‚ â€¢ dashboard_template.pbit (optional)        â”‚
â”‚                                             â”‚
â”‚ Measures Include:                           â”‚
â”‚ â€¢ Total Revenue                             â”‚
â”‚ â€¢ Total Payments                            â”‚
â”‚ â€¢ Payment Rate                              â”‚
â”‚ â€¢ Client Lifetime Value                     â”‚
â”‚ â€¢ Retention Rate                            â”‚
â”‚ â€¢ Revenue Growth MoM                        â”‚
â”‚ â€¢ Active Clients This Month                 â”‚
â”‚ â€¢ Billable Percentage                       â”‚
â”‚ â€¢ Average Invoice                           â”‚
â”‚ â€¢ Outstanding AR                            â”‚
â”‚ â€¢ ... (15 total)                            â”‚
â”‚                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Success Criteria:
- âœ“ All DAX measures syntactically valid
- âœ“ Power Query code tested
- âœ“ Relationships correctly defined
- âœ“ Import guide clear and complete

---

### ğŸš€ **STAGE 10: Deployment Script Generator**

**Type:** Parallel (after Stage 5)  
**Execution Time:** < 1 second  
**Technology:** Bash scripting

#### Input:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SQL DDL                         â”‚
â”‚ from Stage 3                    â”‚
â”‚                                 â”‚
â”‚ CSV Files                       â”‚
â”‚ from Stage 4                    â”‚
â”‚                                 â”‚
â”‚ Enhanced Schema                 â”‚
â”‚ from Stage 2                    â”‚
â”‚                                 â”‚
â”‚ Parameters:                     â”‚
â”‚ â€¢ Target environment (dev/prod) â”‚
â”‚ â€¢ Database type (PostgreSQL)    â”‚
â”‚ â€¢ Host configuration            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Process:

**1. Database Setup Script**
```bash
#!/bin/bash

# Database Creation
psql -U postgres -c "CREATE DATABASE advertising_analytics;"

# Schema Deployment
psql -U postgres -d advertising_analytics -f schema.sql
```

**2. Data Import Script**
```bash
# Import CSVs
for file in *.csv; do
    table_name=${file%.csv}
    psql -U postgres -d advertising_analytics \
        -c "\copy $table_name FROM '$file' CSV HEADER;"
done
```

**3. Performance Optimization**
```bash
# Create Indexes
psql -U postgres -d advertising_analytics <<EOF
CREATE INDEX idx_clients_agency ON Clients(agency_id);
CREATE INDEX idx_invoices_client ON Invoices(client_id);
CREATE INDEX idx_invoices_date ON Invoices(invoice_date);
CREATE INDEX idx_payments_invoice ON Payments(invoice_id);
CREATE INDEX idx_meetings_client ON Meetings(client_id);
CREATE INDEX idx_meetings_date ON Meetings(start_date_time);
ANALYZE;
EOF
```

**4. User & Permission Setup**
```bash
# Create Users
psql -U postgres -d advertising_analytics <<EOF
CREATE USER analytics_user WITH PASSWORD 'secure_password';
GRANT SELECT ON ALL TABLES IN SCHEMA public TO analytics_user;
GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA public TO analytics_user;
EOF
```

**5. Dashboard Deployment**
```bash
# Option A: Streamlit
pip install streamlit plotly pandas psycopg2
streamlit run dashboard.py --server.port 8501

# Option B: Power BI Gateway
# Install from: https://powerbi.microsoft.com/gateway/
# Configure connection string
```

**6. Scheduled Tasks**
```bash
# Add to crontab for daily refresh at 6 AM
echo "0 6 * * * /path/to/refresh_data.sh" | crontab -
```

**7. Health Check Script**
```bash
# Verify deployment
psql -U postgres -d advertising_analytics -c "
    SELECT 
        schemaname,
        tablename,
        pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename))
    FROM pg_tables 
    WHERE schemaname = 'public';"
```

#### Output:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Deployment Package                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                             â”‚
â”‚ Scripts Generated:                          â”‚
â”‚ â€¢ deploy.sh (main deployment script)        â”‚
â”‚ â€¢ setup_database.sh (DB creation)           â”‚
â”‚ â€¢ import_data.sh (CSV import)               â”‚
â”‚ â€¢ create_indexes.sh (optimization)          â”‚
â”‚ â€¢ setup_users.sh (security)                 â”‚
â”‚ â€¢ deploy_dashboard.sh (dashboard setup)     â”‚
â”‚ â€¢ health_check.sh (verification)            â”‚
â”‚ â€¢ rollback.sh (emergency rollback)          â”‚
â”‚                                             â”‚
â”‚ Configuration Files:                        â”‚
â”‚ â€¢ .env.example (environment variables)      â”‚
â”‚ â€¢ config.yaml (deployment config)           â”‚
â”‚ â€¢ requirements.txt (Python dependencies)    â”‚
â”‚                                             â”‚
â”‚ Documentation:                              â”‚
â”‚ â€¢ DEPLOYMENT.md (step-by-step guide)        â”‚
â”‚ â€¢ TROUBLESHOOTING.md (common issues)        â”‚
â”‚ â€¢ MAINTENANCE.md (ongoing operations)       â”‚
â”‚                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Success Criteria:
- âœ“ All scripts executable
- âœ“ Error handling included
- âœ“ Idempotent operations
- âœ“ Rollback capability

---

### ğŸŒ **STAGE 11: Business Context Scraper**

**Type:** Independent (can run anytime)  
**Execution Time:** 5-15 seconds  
**Technology:** Claude API, Web Search

#### Input:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Schema Domain (inferred)        â”‚
â”‚ from Stage 2                    â”‚
â”‚                                 â”‚
â”‚ Optional:                       â”‚
â”‚ â€¢ Industry name                 â”‚
â”‚ â€¢ Company size                  â”‚
â”‚ â€¢ Geographic region             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Process:

**1. Domain Detection**
```javascript
// Analyze table names to infer domain
const domain = inferDomain(schema.tables);
// Result: "Advertising Agency"
```

**2. Claude API Research Request**
```javascript
const research = await fetch('https://api.anthropic.com/v1/messages', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
        model: 'claude-sonnet-4-20250514',
        max_tokens: 2000,
        messages: [{
            role: 'user',
            content: `Research the ${domain} industry and provide:
            
1. Industry Size & Growth
   - Market size (USD)
   - Growth rate (CAGR)
   - Key trends

2. Key Performance Metrics
   - Standard KPIs
   - Industry benchmarks
   - Success metrics

3. Common Pain Points
   - Operational challenges
   - Technology gaps
   - Market pressures

4. Best Practices
   - Client retention strategies
   - Revenue optimization
   - Operational efficiency

5. Technology Stack
   - Common tools
   - Integration patterns
   - Emerging technologies

Provide specific, actionable insights in JSON format.`
        }]
    })
});
```

**3. Response Processing**
```javascript
const context = await research.json();
const insights = context.content[0].text;

// Parse and structure
const structured = {
    industry: domain,
    researched: new Date(),
    insights: insights,
    sources: extractSources(insights)
};
```

#### Output:
```json
{
  "industry": "Advertising Agency",
  "researched": "2025-12-18T10:30:00Z",
  "insights": {
    "marketSize": {
      "global": "$766 billion (2024)",
      "cagr": "6.1% (2024-2029)",
      "keyTrends": [
        "Digital transformation",
        "Data-driven decision making",
        "Personalization at scale"
      ]
    },
    "keyMetrics": {
      "clientRetention": "85-90% industry standard",
      "revenuePerClient": "$50K-$500K annually",
      "staffUtilization": "70-80% billable hours",
      "paymentTerms": "Net 30-45 days typical"
    },
    "painPoints": [
      "Client churn due to lack of data insights",
      "Inefficient staff allocation",
      "Payment delays and AR management",
      "Difficulty demonstrating ROI",
      "Fragmented data across systems"
    ],
    "bestPractices": {
      "clientRetention": [
        "Regular performance reviews with data",
        "Proactive communication of insights",
        "Value demonstration through analytics",
        "Personalized service based on data"
      ],
      "revenueOptimization": [
        "Dynamic pricing based on value",
        "Upselling through data insights",
        "Efficient resource allocation",
        "Quick invoicing and follow-up"
      ]
    },
    "technologyStack": {
      "commonTools": [
        "CRM: Salesforce, HubSpot",
        "Project Management: Asana, Monday.com",
        "Analytics: Tableau, Power BI",
        "Financial: QuickBooks, NetSuite"
      ],
      "emergingTech": [
        "AI-powered analytics",
        "Predictive churn modeling",
        "Real-time dashboards",
        "Automated reporting"
      ]
    }
  }
}
```

**File Output:**
- `business_context.json` (structured)
- `business_context.txt` (readable)
- `business_context.md` (formatted)

#### Success Criteria:
- âœ“ Industry correctly identified
- âœ“ Relevant insights gathered
- âœ“ Actionable recommendations
- âœ“ Current (2024-2025) data

---

## Output: Complete System Package

### ğŸ“¦ Final Deliverables

```
advertising-agency-analytics/
â”‚
â”œâ”€â”€ 01-schema/
â”‚   â”œâ”€â”€ parsed_schema.json
â”‚   â”œâ”€â”€ enhanced_schema.json
â”‚   â””â”€â”€ schema_metadata.json
â”‚
â”œâ”€â”€ 02-database/
â”‚   â”œâ”€â”€ schema.sql
â”‚   â”œâ”€â”€ schema_postgresql.sql
â”‚   â”œâ”€â”€ schema_mysql.sql
â”‚   â””â”€â”€ views.sql
â”‚
â”œâ”€â”€ 03-data/
â”‚   â”œâ”€â”€ agencies.csv
â”‚   â”œâ”€â”€ clients.csv
â”‚   â”œâ”€â”€ staff.csv
â”‚   â”œâ”€â”€ meetings.csv
â”‚   â”œâ”€â”€ invoices.csv
â”‚   â”œâ”€â”€ payments.csv
â”‚   â”œâ”€â”€ staff_in_meetings.csv
â”‚   â””â”€â”€ ref_*.csv (4 files)
â”‚
â”œâ”€â”€ 04-documentation/
â”‚   â”œâ”€â”€ requirements_document.txt
â”‚   â”œâ”€â”€ requirements_document.json
â”‚   â”œâ”€â”€ PRD_advertising_agency_analytics.txt
â”‚   â”œâ”€â”€ PRD_advertising_agency_analytics.pdf
â”‚   â”œâ”€â”€ business_context.json
â”‚   â””â”€â”€ business_context.md
â”‚
â”œâ”€â”€ 05-analytics/
â”‚   â”œâ”€â”€ cohort_analysis.json
â”‚   â”œâ”€â”€ retention_curves.json
â”‚   â”œâ”€â”€ revenue_cohorts.json
â”‚   â””â”€â”€ churn_risk_scores.json
â”‚
â”œâ”€â”€ 06-dashboards/
â”‚   â”œâ”€â”€ executive_dashboard.html
â”‚   â”œâ”€â”€ finance_dashboard.html
â”‚   â”œâ”€â”€ operations_dashboard.html
â”‚   â”œâ”€â”€ sales_dashboard.html
â”‚   â””â”€â”€ components/ (React JSX files)
â”‚
â”œâ”€â”€ 07-powerbi/
â”‚   â”œâ”€â”€ power_bi_measures.dax
â”‚   â”œâ”€â”€ power_bi_date_table.m
â”‚   â”œâ”€â”€ power_bi_instructions.md
â”‚   â”œâ”€â”€ power_bi_relationships.txt
â”‚   â””â”€â”€ dashboard_template.pbit
â”‚
â”œâ”€â”€ 08-deployment/
â”‚   â”œâ”€â”€ deploy.sh
â”‚   â”œâ”€â”€ setup_database.sh
â”‚   â”œâ”€â”€ import_data.sh
â”‚   â”œâ”€â”€ create_indexes.sh
â”‚   â”œâ”€â”€ setup_users.sh
â”‚   â”œâ”€â”€ health_check.sh
â”‚   â”œâ”€â”€ rollback.sh
â”‚   â”œâ”€â”€ .env.example
â”‚   â”œâ”€â”€ config.yaml
â”‚   â”œâ”€â”€ DEPLOYMENT.md
â”‚   â”œâ”€â”€ TROUBLESHOOTING.md
â”‚   â””â”€â”€ MAINTENANCE.md
â”‚
â””â”€â”€ 09-reports/
    â”œâ”€â”€ execution_summary.md
    â”œâ”€â”€ data_quality_report.json
    â””â”€â”€ system_architecture.pdf
```

**Total Files:** 50+  
**Total Size:** ~5-10 MB  
**Documentation Pages:** ~100

---

## Execution Timeline

### Sequential Path (Critical Path)
```
Stage 1 (Vision API)       [5-10s]
    â†“
Stage 2 (Schema)           [<1s]
    â†“
Stage 3 (SQL)              [<1s]
    â†“
Stage 4 (Data)             [2-5s]
    â†“
Stage 5 (Requirements)     [<1s]
    
Total Sequential: 8-17 seconds
```

### Parallel Path (After Stage 5)
```
Stage 6 (PRD)              [<1s]  â”
Stage 7 (Analytics)        [1-2s] â”‚
Stage 8 (Dashboards)       [<1s]  â”œâ”€ Execute in parallel
Stage 9 (Power BI)         [<1s]  â”‚
Stage 10 (Deploy)          [<1s]  â”˜

Total Parallel: 1-2 seconds (longest task)
```

### Independent
```
Stage 11 (Context)         [5-15s] - Can run anytime
```

### **Total Execution Time: 9-19 seconds**
*(Excluding Stage 11 which is optional)*

---

## System Requirements

### Hardware
- **CPU:** 2+ cores recommended
- **RAM:** 4GB minimum, 8GB recommended
- **Storage:** 100MB for system, 1GB for data
- **Network:** Stable internet for API calls

### Software
- **Node.js:** v16+ or **Python:** 3.8+
- **PostgreSQL:** 12+ or **MySQL:** 8+
- **Optional:** Power BI Desktop, Tableau
- **Browser:** Chrome/Firefox/Safari (latest)

### API Requirements
- **Anthropic API Key** (for Vision & Context)
- **Rate Limits:** 50 requests/minute

---

## Error Handling & Recovery

### Stage-Level Error Handling

**Stage 1 (Vision API):**
- **Timeout:** Retry with exponential backoff (3 attempts)
- **Invalid Image:** Return clear error, request new image
- **Incomplete Parse:** Flag for manual review, continue with partial

**Stage 2-3 (Schema/SQL):**
- **Validation Failure:** Log errors, attempt auto-fix
- **Circular Dependency:** Break cycle, notify user
- **Invalid SQL:** Syntax check, generate warning

**Stage 4 (Data):**
- **FK Violation:** Re-generate affected records
- **Data Type Mismatch:** Coerce or generate new
- **Size Limits:** Reduce row counts, notify user

**Stage 5-10 (Documents/Outputs):**
- **Template Error:** Use fallback template
- **File Write Error:** Retry with temp directory
- **API Failure:** Cache and retry, use defaults

### Recovery Mechanisms
1. **Checkpointing:** Save progress after each stage
2. **Rollback:** Revert to last successful stage
3. **Partial Success:** Allow completion with warnings
4. **Manual Override:** User can skip/modify stages

---

## Quality Assurance

### Automated Tests
- **Schema Validation:** All FKs resolvable
- **SQL Syntax Check:** Execute in test database
- **Data Integrity:** Check all FK references
- **Dashboard Rendering:** Automated screenshot comparison
- **Documentation:** Spell check, link validation

### Manual Review Points
1. **Post-Stage 1:** Verify all tables extracted
2. **Post-Stage 4:** Sample data quality check
3. **Post-Stage 8:** Dashboard usability review
4. **Pre-Deployment:** Security audit

---

## Performance Optimization

### Optimization Strategies
1. **Parallel Processing:** Stages 6-10 run concurrently
2. **Caching:** Schema parsed once, reused
3. **Lazy Loading:** Generate on-demand where possible
4. **Incremental Updates:** Only regenerate changed components

### Scalability Considerations
- **Small Schema (< 10 tables):** 8-12 seconds total
- **Medium Schema (10-30 tables):** 12-20 seconds total
- **Large Schema (30+ tables):** 20-40 seconds total

---

## Version Control & Tracking

### Versioning
```
v1.0.0 - Initial generation
v1.1.0 - Schema updated (added 2 tables)
v1.1.1 - Data regenerated
v2.0.0 - Major schema refactor
```

### Change Tracking
```json
{
  "version": "1.1.0",
  "changes": [
    {
      "stage": "Schema",
      "type": "addition",
      "description": "Added Marketing_Campaigns table",
      "timestamp": "2025-12-18T11:00:00Z"
    }
  ],
  "regenerated": ["SQL", "Data", "Dashboards"]
}
```

---

## Conclusion

This workflow design provides a complete, production-ready system for transforming ER diagrams into analytics platforms. The modular design allows for:

- **Flexibility:** Stages can be run independently or together
- **Speed:** Parallel processing reduces total time
- **Reliability:** Error handling at every stage
- **Scalability:** Handles schemas from 5 to 50+ tables
- **Completeness:** Everything from parsing to deployment

**Next Steps:**
1. Review and approve this design
2. Begin implementation of Stage 1 (Vision API)
3. Develop sequential stages 2-5
4. Implement parallel stages 6-10
5. Add Stage 11 (Context Scraper)
6. Integration testing
7. Production deployment

---

**Document Version:** 1.0  
**Last Updated:** December 18, 2025  
**Status:** Ready for Implementation